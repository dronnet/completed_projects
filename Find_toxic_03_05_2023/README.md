Краткое описание задачи:

Нужено создать инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.

Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.

Постройте модель со значением метрики качества F1 не меньше 0.75.


-- -- 
Данные:
Одна таблица, 160 000 строк.
Данные находятся в файле toxic_comments.csv. Столбец text в нём содержит текст комментария, а toxic — целевой признак.


-- --
Использованы следующие библиотеки:

os, numpy, pandas, spacy, torch, transformers, tqdm, sklearn, catboost, re.
